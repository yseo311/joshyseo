mentions3 <- str_replace_all(mentions2, '@', "")
mentions2[3] <- mentions3
i = 1:400000
mentions2[3,i] <- mentions3[i]
i = 1:40000
mentions2[3,i] <- mentions3[i]
i = 1:40000
mentions2[i,3] <- mentions3[i]
i = 1:40000
mentions2[i] <- mentions3[i]
View(mentions2)
grep("@[[:punct:]]", tweet$content, value = FALSE)
mentiosn4 <- grep("@[[:punct:]]", tweet$content, value = FALSE)
mentiosn4 <- grep("@[[:punct:]]", tweet$content, value = TRUE)
mentiosn4
mentions <- str_replace_all(tweet$content, "@[[:punct:]]", "")
View(mention)
View(mention)
hash_tags <- str_extract_all(tweet$content, "[#\\w{1,}]")
mention_count <- table(sapply(hash_tags, length))
count_hash <- table(num_hash)
hash_tags <- str_extract_all(tweet$content, "[#\\w{1,}]")
num_hash <- table(sapply(hash_tags, length))
count_hash <- table(num_hash)
barplot(count_hash)
summary(count_hash)
summary(num_hash)
mean(num_hash)
mode(num_hash)
mode(hash_tags)
setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04/report")
png("../image/dplyr-archive.png", plot_archive(clean_data_dplyr))
?png
plot_archive(clean_data_dplyr) %>%
png("../image/dplyr-archive.png")
########################################################################################
#Prep
#setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04/code")
#install.packages("XML")
#rm(list=ls())
library(XML)
library(dplyr)
library(stringr)
library(ggplot2)
########################################################################################
#read_archive#
read_archive <- function(x){
complete_url <- paste0('http://cran.r-project.org/src/contrib/Archive/',x)
tbl_html <- readHTMLTable(complete_url)
data.frame(tbl_html)
}
raw_data <- read_archive('stringr')
raw_data
#read_archive_end#
#clean_archive#
version_names = function(a){
str_sub(
unlist(str_split(a$NULL.Name, pattern = '_' ))[c(TRUE, FALSE)]
)
}
version_numbers = function(a){
str_sub(
str_replace(
unlist(str_split(a$NULL.Name, pattern = '_' ))[c(FALSE, TRUE)],
pattern = '.tar.gz',
replacement = ''
)
)
}
version_dates = function(a){
str_sub(a$NULL.Last.modified, end = -7)
}
version_sizes = function(a){
size_value <- as.numeric(str_replace(a$NULL.Size, pattern = "K|M", replacement = ''))
size_unit <- str_sub(a$NULL.Size, start = -1)
which_size_unit <- size_unit == "M"
size_value[which_size_unit] <- size_value[which_size_unit] * 1000
a$NULL.Size <- size_value
}
clean_archive <- function(y){
y$NULL.Description <- NULL
index<- which(is.na(y$NULL.Size))
y <- y[-c(2,index),]
y <- data.frame(
as.character(version_names(y)),
as.character(version_numbers(y)),
as.Date(version_dates(y)),
as.numeric(version_sizes(y))
)
colnames(y) <- c("name", "version", "date", "size")
return(y)
}
write.table(clean_archive(raw_data), file = "../data/splyr-archive.csv",
sep = ",",
col.names = TRUE,
row.names = FALSE)
z <- clean_archive(raw_data)
#clean_archive_END#
#PLOTTING#
plot_archive <- function(z){
ggplot(data = z) +
geom_step(aes(x = z$date, y = z$size)) +
ggtitle("timeline of version sizes") +
xlab("date") + ylab("Size (Kilobytes)")
}
plot_archive(z)
#PLOTTING_END#
#setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04/report")
source('../code/archive-functions.R')
raw_data <- read_archive('stringr')
clean_data <- clean_archive(raw_data)
plot_archive(clean_data)
raw_data_dplyr <- read_archive('dplyr')
clean_data_dplyr <- clean_archive(raw_data_dplyr)
plot_archive(clean_data_dplyr)
plot_archive(clean_data_dplyr) %>%
png("../image/dplyr-archive.png")
plot_archive(clean_data_dplyr) -> png("../image/dplyr-archive.png")
"../image/dplyr-archive.png" <- plot_archive(clean_data_dplyr)
"../images/dplyr-archive.png" <- plot_archive(clean_data_dplyr)
plot_archive(clean_data_dplyr) %>%
png("../images/dplyr-archive.png"
png("../images/dplyr-archive.png",
rm(list=ls())
setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04/code")
########################################################################################
#Prep
#setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04/code")
#install.packages("XML")
#rm(list=ls())
library(XML)
library(dplyr)
library(stringr)
library(ggplot2)
########################################################################################
#read_archive#
read_archive <- function(x){
complete_url <- paste0('http://cran.r-project.org/src/contrib/Archive/',x)
tbl_html <- readHTMLTable(complete_url)
data.frame(tbl_html)
}
raw_data <- read_archive('stringr')
raw_data
#read_archive_end#
#clean_archive#
version_names = function(a){
str_sub(
unlist(str_split(a$NULL.Name, pattern = '_' ))[c(TRUE, FALSE)]
)
}
version_numbers = function(a){
str_sub(
str_replace(
unlist(str_split(a$NULL.Name, pattern = '_' ))[c(FALSE, TRUE)],
pattern = '.tar.gz',
replacement = ''
)
)
}
version_dates = function(a){
str_sub(a$NULL.Last.modified, end = -7)
}
version_sizes = function(a){
size_value <- as.numeric(str_replace(a$NULL.Size, pattern = "K|M", replacement = ''))
size_unit <- str_sub(a$NULL.Size, start = -1)
which_size_unit <- size_unit == "M"
size_value[which_size_unit] <- size_value[which_size_unit] * 1000
a$NULL.Size <- size_value
}
clean_archive <- function(y){
y$NULL.Description <- NULL
index<- which(is.na(y$NULL.Size))
y <- y[-c(2,index),]
y <- data.frame(
as.character(version_names(y)),
as.character(version_numbers(y)),
as.Date(version_dates(y)),
as.numeric(version_sizes(y))
)
colnames(y) <- c("name", "version", "date", "size")
return(y)
}
write.table(clean_archive(raw_data), file = "../data/splyr-archive.csv",
sep = ",",
col.names = TRUE,
row.names = FALSE)
z <- clean_archive(raw_data)
#clean_archive_END#
#PLOTTING#
plot_archive <- function(z){
ggplot(data = z) +
geom_step(aes(x = z$date, y = z$size)) +
ggtitle("timeline of version sizes") +
xlab("date") + ylab("Size (Kilobytes)")
}
plot_archive(z)
#PLOTTING_END#
#2.1) Splitting Characters
split_chars <- function(x) {
func <- strsplit(x, "")
return(unlist(func))
}
split_chars('Go Bears!')
split_chars('Expecto Patronum')
#2.2) Number of Vowels
vowels <- c("a","e","i","o","u")
num_vowels <- function(y){
num_vowels = vector(mode = "integer", length = 5)
for (j in seq_along(vowels)) {
num_aux = str_count(tolower(y), vowels[j])
num_vowels[j] = sum(num_aux)
}
names(num_vowels) = vowels
num_vowels
}
vec <- c('G','o','','B','e','a','r','s','!')
num_vowels(vec)
#2.3) Counting Vowels
count_vowels <- function(z){
z <- tolower(z)
character <- split_chars(z)
vowel <- num_vowels(character)
return(vowel)
}
count_vowels("The quick brown fox jumps over the lazy dog")
count_vowels("THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG")
#2.4) Reversing Characters
reverse_chars <- function(string)
{
string_split = strsplit(string, split = "")
rev_order = nchar(string):1
reversed_chars = string_split[[1]][rev_order]
paste(reversed_chars, collapse="")
}
reverse_chars("gattaca")
reverse_chars("Lumox Maxima")
#2.5) Reversing Sentences by Words
reverse_words <- function(string)
{
string_split = strsplit(as.character(string), split = " ")
string_length = length(string_split[[1]])
if (string_length == 1) {
reversed_string = string_split[[1]]
} else {
reversed_split = string_split[[1]][string_length:1]
reversed_string = paste(reversed_split, collapse = " ")
}
return(reversed_string)
}
reverse_words("sentence! this reverse")
reverse_words("string")
setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04")
setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04")
#setwd("C:/Users/SEO/Desktop/Josh/School/UCB/Spring 2018/Stat 133/hw-stat133/hw04")
source('../code/archive-functions.R')
knitr::opts_chunk$set(echo = TRUE, error = TRUE, fig.path = '../images/')
raw_data <- read_archive('stringr')
clean_data <- clean_archive(raw_data)
plot_archive(clean_data)
raw_data_dplyr <- read_archive('dplyr')
clean_data_dplyr <- clean_archive(raw_data_dplyr)
plot_archive(clean_data_dplyr)
write.table(clean_archive(raw_data_dplyr), file = "../data/dplyr-archive.csv",
sep = ",",
col.names = TRUE,
row.names = FALSE)
raw_data_ggplot <- read_archive('ggplot2')
clean_data_ggplot <- clean_archive(raw_data_ggplot)
plot_archive(clean_data_ggplot)
plot_archive(clean_data_ggplot)
write.table(clean_archive(raw_data_ggplot), file = "../data/ggplot-archive.csv",
sep = ",",
col.names = TRUE,
row.names = FALSE)
raw_data_XML <- read_archive('XML')
clean_data_XML <- clean_archive(raw_data_XML)
plot_archive(clean_data_XML)
plot_archive(clean_data_XML)
write.table(clean_archive(raw_data_XML), file = "../data/xml-archive.csv",
sep = ",",
col.names = TRUE,
row.names = FALSE)
raw_data_knitr <- read_archive('knitr')
clean_data_knitr <- clean_archive(raw_data_knitr)
plot_archive(clean_data_knitr)
plot_archive(clean_data_knitr)
write.table(clean_archive(raw_data_knitr), file = "../data/knir-archive.csv",
sep = ",",
col.names = TRUE,
row.names = FALSE)
#merge dataframe
library(ggplot2)
combined_data <-
rbind.data.frame(clean_data_dplyr, clean_data_ggplot, clean_data_XML, clean_data_knitr)
#merged plot
ggplot(combined_data, aes(x = date, y = size)) +
geom_step(aes(col = name)) +
ggtitle("timeline of version sizes") +
xlab("date") + ylab("Size (KB)")
#faceted plot
ggplot(combined_data, aes(x = date, y = size)) +
geom_step(aes(col = name)) +
facet_wrap(~name, scales="free") +
ggtitle("timeline of version sizes") +
xlab("date") + ylab("Size (KB)")
tweet <- read.csv("https://raw.githubusercontent.com/ucb-stat133/stat133-spring-2018/master/data/text-emotion.csv", stringsAsFactors = FALSE)
#count the number of characters per tweet
chars_per_tweet <- nchar(tweet$content)
summary(chars_per_tweet)
#plot a histogram
hist(chars_per_tweet,
main = "Histogram of number of characters in tweet",
xlab = "Number of Characters",
col = "lavender",
xlim = c(0, 200),
breaks = 50)
mention2 <- grep("@[$\\w]{1,16}", tweet, value = TRUE)
mention2 <- grep("@[\\w]{1,16}", tweet, value = TRUE)
mention <- str_extract_all(tweet$content, '@[$\\W]{1,16}', TRUE)
View(mention)
mention <- str_extract_all(tweet$content, '@[\\W]{1,16}', TRUE)
View(mention)
mention <- str_extract_all(tweet$content, '@\\W{1,16}')
View(mention)
mention <- str_extract_all(tweet$content, '@\\w{1,16}')
View(mention)
mention <- str_extract_all(tweet$content, '[^@}[\\w]{1,16}$[\\W]')
mention <- str_extract_all(tweet$content, '[^@}[\\w]$[\\W]{1,16}')
mention <- str_extract_all(tweet$content, '[^@}[\\w][$[\\W]]{1,16}')
mention <- str_extract_all(tweet$content, '[^@][\\w][$[\\W]]{1,16}')
View(mention)
mention <- str_extract_all(tweet$content, '[^@][\\w][$[\\W]]{1,16}')
View(mention)
mention <- str_extract_all(tweet$content, '[^@][\\w]{1,16} & [$[\\W]]')
View(mention)
mention <- str_extract_all(tweet$content, '[^@][\\w]{1,16} & [$[\\W]]')
View(mention)
mention <- str_extract_all(tweet$content, '[^@][\\w]{1,16} & [$[\\w]]')
View(mention)
mention <- str_extract_all(tweet$content, '@[$[\\w]]')
View(mention)
grep("[$[\\w]]", tweet)
mention2 <- grep("[$[\\w]]", tweet, value = TRUE)
mention2 <- grep("@[$[\\w]]", tweet, value = TRUE)
mention2
mention <- str_extract_all(tweet$content, '@[\\w]{1,16}[\\w]{1,16}')
View(mention)
mention <- str_extract_all(tweet$content, '@[\\w]{1,16}[\\w]{1,16}')
mention_count <- sapply(mention, length)
mention_table <- table(mention_count)
mention_table
barplot(mention_table)
rm(mention2)
f(10, mention)
grep("10", mention)
grep("character[10]", mention)
lapply(mention, "10")
lapply(mention, 10)
lapply(mention, 1)
apply(mention, 1)
apply(mention, 1, max)
apply(mention, length = 10, value)
apply(mention, "length = 10", value)
grep(mention, 10, TRUE)
grep(mention, ?=10, TRUE)
grep(mention, "?=10", TRUE)
View(mention)
?list.search
help(list.search)
grep(mention, class(character(10)), TRUE)
regmatches(mention, regexpr(10, mention))
regmatches(mention, regexpr(10, mention_count))
regmatches(mention, gregexpr(10, mention_count))
regmatches(mention, gregexpr(10, mention))
regmatches(mention, gregexpr("", mention))
regmatches(mention, length(10))
regmatches(mention, length)
greg(length(mention)=10, mention)
greg(length = 10, mention)
greg("length = 10", mention)
library(stringr)
greg("length = 10", mention)
greg("length(mention) = 10", mention)
grep("length(mention) = 10", mention)
length(mention[1])
length(mention[277])
length(mention[50])
summary(mention[50])
summary(mention[277])
length(mention[277])
summary(mention[277])
mention[277]
summary(mention[277])
which.max(length > 9)
which(mention = 10)
position(mention, _?(mention > 10))
position(mention, ?(mention > 10))
position(mention, ?(length > 10))
lenghts(mention)
length(mention)
length(mention[277])
count(mention[277])
summary(mention[277])
mention[277]
size(mention[1])
mention_count
which(mention_count=10)
length(mention_count[1])
length(mention_count[157])
position(mention_count, ?(length > 10))
lapply(mention, max)
lapply(mention, min, 10)
lapply(mention, max, 10)
lapply(mention, length, 10)
lapply(mention, lengths, 10)
lapply(mention, lengths, 10)
sapply(mention, max)
summary(mention[40000])
summary(mention[30000])
table(summary(mention[30000]))
summary(mention[30000])
summary(mention[19999])
summary(mention[1999])
typeof(mention[1])
class(mention[1])
print(max(mention, key=len))
print(max(mention, key=length))
which(mention_count = 10)
max(mention_count)
which(max(mention_count))
print(max(mention_count))
summary(mention_count)
str_match(mention_count, 10)
str_match(mention_count, "10"")
str_match(mention_count, "10")
str_match_all(mention_count, mention_count == 10)
str_match_all(mention_count, value = 10)
str_match_all(mention_count, value == 10)
which.max(mention_count)
mention[i]
i <- which.max(mention_count)
mention[i]
plot_ly(x = mention_count,
y = frequency(mention_count),
type = 'bar')
plot_ly(x = mention_count,
y = frequency,
type = 'bar')
hist(mention_table)
barplot(mention_table)
mention[i]
hash_tags <- str_extract_all(tweet$content, pattern = "#\\w{1,}")
View(hash_tags)
hash_count <-sapply(hash_tags, length)
hash_table <- table(hash_count)
barplot(hash_table)
mean(hash_count)
View(hash_tags)
hash_tags <- str_extract_all(tweet$content, pattern = "#[[:alnum:]]{1,}[[:alnum:]]{1,}")
View(hash_tags)
View(hash_tags)
hash_count <-sapply(hash_tags, length)
hash_table <- table(hash_count)
barplot(hash_table)
hash_table
mean(hash_count)
View(hash_tags)
length(hash_tags[23])
hash_tags[23]
width(hash_tags[23])
nchar(hash_tags)
hash_length <- nchar(hash_tags, type = "chars", allowNA = FALSE)
hash_length <- nchar(hash_tags, allowNA = FALSE)
str_replace_all(hash_tags, "character", "")
str_replace_all(hash_tags, "character" & "(0)", "")
str_replace_all(hash_tags, "character & (0)", "")
str_replace_all(hash_tags, "character(0)", "")
hash_only <- str_replace_all(hash_tags, "character", "")
hash_length <- nchar(hash_tags, type = "chars", allowNA = FALSE)
hash_length <- nchar(hash_tags, type = "chars", allowNA = FALSE)
hash_length <- nchar(hash_only, type = "chars", allowNA = FALSE)
hash_only <- str_replace_all(hash_tags, "character" | "(" | ")", "")
hash_only <- str_replace_all(hash_tags, "character" | "(\\" | "\\)", "")
hash_only <- str_replace_all(hash_tags, "character | (\\ | \\)", "")
hash_tags[1]
hash_tags[23]
hash_only <- str_replace_all(hash_tags, "character(0)", "")
hash_tags[1]
hash_only <- str_replace_all(hash_tags, "character[0]", "")
hash_only <- str_replace_all(hash_tags, "character[0]", "")
View(hash_tags)
hash_only
hash_only <- str_replace_all(hash_tags, "character(0)", "")
hash_only <- str_replace_all(hash_tags, "[character][(0)]", "")
hash_only <- str_replace_all(hash_tags, "[character(0)]", "")
hash_only
hash_length <- nchar(hash_only, type = "chars", allowNA = FALSE)
hash_length
tags_only <- str_rplace_all(hash_only, "[#]", "")
tags_only <- str_rplace_all(hash_only, "#", "")
tags_only <- str_replace_all(hash_only, "[#]", "")
hash_length <- nchar(tags_only, type = "chars", allowNA = FALSE)
hash_length
mean(hash_length)
table(hash_length)
summary(hash_length)
mean(hash_length)
table(hash_length)
which.max(hash_length)
which(which.max(hash_length))
which(hash_length, which.max(hash_length))
which(hash_length = 30930)
